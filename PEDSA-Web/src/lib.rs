use wasm_bindgen::prelude::*;
use aho_corasick::{AhoCorasick, AhoCorasickBuilder, MatchKind};
use ahash::AHashMap;
use smallvec::SmallVec;
// use rayon::prelude::*;
// use std::time::Instant;
use std::hash::{Hash, Hasher};
use twox_hash::XxHash64;
use half::f16;

// mod storage; // Storage logic is disabled for WASM build to avoid I/O dependencies
mod embedding;
mod storage_bridge;
use embedding::StaticModel;

#[wasm_bindgen]
extern "C" {
    #[wasm_bindgen(js_namespace = console)]
    fn log(s: &str);
}

// Macro for console.log
#[allow(unused_macros)]
macro_rules! console_log {
    ($($t:tt)*) => (log(&format!($($t)*)))
}

// ============================================================================
// 1. è¯­ä¹‰æŒ‡çº¹ (SimHash V2: Partitioned Multimodal)
// ============================================================================

#[wasm_bindgen]
pub struct SimHash;

impl SimHash {
    pub const MASK_SEMANTIC: u64 = 0xFFFFFFFF;
    pub const MASK_TEMPORAL: u64 = 0xFFFF00000000; // [32-47]: æ—¶é—´åŒº (Temporal only - Location removed in V3)
    pub const MASK_AFFECTIVE: u64 = 0x00FF000000000000;
    pub const MASK_TYPE: u64 = 0xFF00000000000000;

    // --- Entity Type Constants ---
    pub const TYPE_UNKNOWN: u8 = 0x00;
    pub const TYPE_PERSON: u8 = 0x01;    // äººç‰©/èº«ä»½
    pub const TYPE_TECH: u8 = 0x02;      // æŠ€æœ¯/æ¦‚å¿µ
    pub const TYPE_EVENT: u8 = 0x03;     // äº‹ä»¶/åŠ¨ä½œ
    pub const TYPE_LOCATION: u8 = 0x04;  // åœ°ç‚¹
    pub const TYPE_OBJECT: u8 = 0x05;    // ç‰©ä»¶
    pub const TYPE_VALUES: u8 = 0x06;    // ä»·å€¼è§‚

    // --- Edge Type Constants (V3.5 Typed Edges - Simplified) ---
    pub const EDGE_REPRESENTATION: u8 = 0; // è¡¨å¾ (Representation) - "çœ‹åˆ° B å¯èƒ½ä¼šæƒ³åˆ° A" (å•å‘/éç­‰ä»·)
    pub const EDGE_EQUALITY: u8 = 1;       // ç­‰ä»· (Equality) - "A å°±æ˜¯ B" (åŒå‘/é›¶æŸè€—)
    pub const EDGE_INHIBITION: u8 = 255;   // æŠ‘åˆ¶ (Inhibition) - "A ä¸ B äº’æ–¥" (åŒå‘/è´Ÿåé¦ˆ)

    // --- Affective Constants (Plutchik's Wheel Bitmap - Adjusted) ---
    pub const EMOTION_JOY: u8          = 1 << 0; // å–œæ‚¦
    pub const EMOTION_SHY: u8          = 1 << 1; // å®³ç¾
    pub const EMOTION_FEAR: u8         = 1 << 2; // å®³æ€•
    pub const EMOTION_SURPRISE: u8     = 1 << 3; // æƒŠè®¶
    pub const EMOTION_SADNESS: u8      = 1 << 4; // éš¾è¿‡
    pub const EMOTION_DISGUST: u8      = 1 << 5; // è®¨åŒ
    pub const EMOTION_ANGER: u8        = 1 << 6; // ç”Ÿæ°”
    pub const EMOTION_ANTICIPATION: u8 = 1 << 7; // æœŸå¾…
}

#[wasm_bindgen]
impl SimHash {
    /// è®¡ç®—å¤šæ¨¡æ€åˆ†åŒºæŒ‡çº¹ (64-bit)
    pub fn compute_multimodal_wasm(text: &str, timestamp: u64, emotion_val: u8, type_val: u8) -> u64 {
        Self::compute_multimodal(text, timestamp, emotion_val, type_val)
    }
    
    pub fn compute_for_query_wasm(query: &str, ref_time: u64) -> u64 {
        Self::compute_for_query(query, ref_time)
    }

    /// JS compatible quantization (f32 array -> hex string)
    pub fn quantize_vector_js(vec: &[f32]) -> String {
        let val = Self::quantize_vector_f32(vec);
        format!("{:032x}", val)
    }
}

impl SimHash {
    /// å‘é‡äºŒå€¼åŒ–é‡åŒ– (128-dim f16 -> 128-bit u128)
    pub fn quantize_vector(vec: &[f16]) -> u128 {
        let mut fp: u128 = 0;
        for (i, &val) in vec.iter().enumerate().take(128) {
            if val.to_f32() > 0.0 {
                fp |= 1 << i;
            }
        }
        fp
    }

    pub fn quantize_vector_f32(vec: &[f32]) -> u128 {
        let mut fp: u128 = 0;
        for (i, &val) in vec.iter().enumerate().take(128) {
            if val > 0.0 {
                fp |= 1 << i;
            }
        }
        fp
    }
}

impl SimHash {
    /// è®¡ç®—å¤šæ¨¡æ€åˆ†åŒºæŒ‡çº¹ (64-bit)
    /// [0-31]: è¯­ä¹‰åŒº (Text)
    /// [32-47]: æ—¶é—´åŒº (Temporal)
    /// [48-55]: æƒ…æ„ŸåŒº (Affective)
    /// [56-63]: ç±»å‹åŒº (Entity Type)
    pub fn compute_multimodal(text: &str, timestamp: u64, emotion_val: u8, type_val: u8) -> u64 {
        let mut fp = 0u64;

        // 1. è¯­ä¹‰åŒº [0-31] (32 bits)
        let semantic_hash = Self::compute_text_hash_32(text);
        fp |= (semantic_hash as u64) & Self::MASK_SEMANTIC;

        // 2. æ—¶é—´åŒº [32-47] (16 bits) - ä»…ä¿ç•™æ—¶é—´
        if timestamp > 0 {
            let t_hash = Self::compute_temporal_hash(timestamp);
            fp |= ((t_hash as u64) << 32) & Self::MASK_TEMPORAL;
        }

        // 3. æƒ…æ„ŸåŒº [48-55] (8 bits)
        fp |= ((emotion_val as u64) << 48) & Self::MASK_AFFECTIVE;

        // 4. ç±»å‹åŒº [56-63] (8 bits)
        fp |= ((type_val as u64) << 56) & Self::MASK_TYPE;

        fp
    }

    /// é’ˆå¯¹æŸ¥è¯¢å­—ç¬¦ä¸²çš„æ™ºèƒ½æŒ‡çº¹ç”Ÿæˆ (Enhanced Temporal Awareness)
    /// ref_time: å¤–éƒ¨ä¼ å…¥çš„å‚è€ƒæ—¶é—´æˆ³ï¼ˆç°å®æ—¶é—´æˆ–å™äº‹æ—¶é—´ï¼‰ï¼Œç”¨äºè§£æç›¸å¯¹æ—¶é—´
    pub fn compute_for_query(query: &str, ref_time: u64) -> u64 {
        let mut timestamp = 0u64;
        let mut emotion = 0u8;
        let mut type_val = Self::TYPE_UNKNOWN;

        let query_lower = query.to_lowercase();

        // --- 1. ç›¸å¯¹æ—¶é—´è§£æ (Relative Time Resolution) ---
        // åªæœ‰å½“ ref_time æœ‰æ•ˆ (>0) æ—¶æ‰å¯ç”¨ç›¸å¯¹æ—¶é—´è§£æ
        if ref_time > 0 {
            // 0. ä»Šå¤©/ä»Šæ—¥/æ­¤åˆ» (Present)
            if query_lower.contains("ä»Šå¤©") || query_lower.contains("ä»Šæ—¥") || query_lower.contains("today") || 
               query_lower.contains("now") || query_lower.contains("æ­¤åˆ»") || query_lower.contains("å½“å‰") {
                timestamp = ref_time;
            }
            // 1. æ˜¨å¤©/æ˜¨æ—¥ (1 Day Ago)
            else if query_lower.contains("æ˜¨å¤©") || query_lower.contains("æ˜¨æ—¥") || query_lower.contains("yesterday") {
                timestamp = ref_time.saturating_sub(86400);
            }
            // 2. å‰å¤©/å‰æ—¥ (2 Days Ago)
            else if query_lower.contains("å‰å¤©") || query_lower.contains("å‰æ—¥") {
                timestamp = ref_time.saturating_sub(172800);
            }
            // 3. å¤§å‰å¤© (3 Days Ago)
            else if query_lower.contains("å¤§å‰å¤©") {
                timestamp = ref_time.saturating_sub(259200);
            }
            // 4. å‰å‡ å¤©/Recently (Approx 3 Days Ago) - æ¨¡ç³ŠåŒ¹é…
            else if query_lower.contains("å‰å‡ å¤©") || query_lower.contains("æœ€è¿‘") || query_lower.contains("recently") {
                timestamp = ref_time.saturating_sub(259200);
            }
            // 5. ä¸Šå‘¨/Last Week (7 Days Ago)
            else if query_lower.contains("ä¸Šå‘¨") || query_lower.contains("last week") {
                timestamp = ref_time.saturating_sub(604800);
            }
            // 6. ä¸Šä¸ªæœˆ/Last Month (30 Days Ago)
            else if query_lower.contains("ä¸Šä¸ªæœˆ") || query_lower.contains("ä¸Šæœˆ") || query_lower.contains("last month") {
                timestamp = ref_time.saturating_sub(2592000);
            }
            // 7. å»å¹´/Last Year (365 Days Ago)
            else if query_lower.contains("å»å¹´") || query_lower.contains("last year") {
                timestamp = ref_time.saturating_sub(31536000); 
            }
            // 8. å‰å¹´ (2 Years Ago)
            else if query_lower.contains("å‰å¹´") {
                timestamp = ref_time.saturating_sub(63072000); 
            }
            // 9. åˆšæ‰/åˆšåˆš (Just Now - 1 min ago)
            else if query_lower.contains("åˆšæ‰") || query_lower.contains("åˆšåˆš") || query_lower.contains("just now") {
                timestamp = ref_time.saturating_sub(60); 
            }
            // 10. æ—©ä¸Š/ä¸Šåˆ (Morning - Assume 9:00 AM of current day)
            // è¿™æ˜¯ä¸€ä¸ªç²—ç•¥çš„é”šç‚¹ï¼Œå¦‚æœ ref_time å·²ç»æ˜¯å½“å¤©ï¼Œæˆ‘ä»¬å…¶å®åªéœ€è¦å½“å¤©çš„æ—¥æœŸéƒ¨åˆ†
            // ä½†ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œæš‚æ—¶æŒ‡å‘ ref_time (å½“å¤©)
            else if query_lower.contains("æ—©ä¸Š") || query_lower.contains("ä¸Šåˆ") || query_lower.contains("morning") {
                 timestamp = ref_time; 
            }
        }

        // --- 2. ç»å¯¹æ—¶é—´è§£æ (Absolute Time Fallback) ---
        // åªæœ‰åœ¨ç›¸å¯¹æ—¶é—´æœªå‘½ä¸­æ—¶æ‰å°è¯•ç»å¯¹å¹´ä»½åŒ¹é…
        if timestamp == 0 {
            if query_lower.contains("2024") { timestamp = 1704067200; } // 2024-01-01
            if query_lower.contains("2025") { timestamp = 1735689600; } // 2025-01-01
            if query_lower.contains("2026") { timestamp = 1767225600; } // 2026-01-01
        }
        
        // Mock Emotion Extraction (Plutchik's Wheel)
        if query_lower.contains("å¼€å¿ƒ") || query_lower.contains("æ¬£æ…°") || query_lower.contains("æ£’") || query_lower.contains("æˆåŠŸ") { 
            emotion |= Self::EMOTION_JOY; 
        }
        if query_lower.contains("å®³ç¾") || query_lower.contains("ä¸å¥½æ„æ€") || query_lower.contains("è„¸çº¢") { 
            emotion |= Self::EMOTION_SHY; 
        }
        if query_lower.contains("å®³æ€•") || query_lower.contains("æ‹…å¿ƒ") || query_lower.contains("ç„¦è™‘") { 
            emotion |= Self::EMOTION_FEAR; 
        }
        if query_lower.contains("æ²¡æƒ³åˆ°") || query_lower.contains("ç«Ÿç„¶") || query_lower.contains("æƒŠè®¶") { 
            emotion |= Self::EMOTION_SURPRISE; 
        }
        if query_lower.contains("éš¾è¿‡") || query_lower.contains("ä½è½") || query_lower.contains("å¤±æœ›") || query_lower.contains("é—æ†¾") { 
            emotion |= Self::EMOTION_SADNESS; 
        }
        if query_lower.contains("è®¨åŒ") || query_lower.contains("ä¸å–œæ¬¢") || query_lower.contains("çƒ‚") { 
            emotion |= Self::EMOTION_DISGUST; 
        }
        if query_lower.contains("ç”Ÿæ°”") || query_lower.contains("æ¼ç«") || query_lower.contains("ä¸çˆ½") { 
            emotion |= Self::EMOTION_ANGER; 
        }
        if query_lower.contains("æœŸå¾…") || query_lower.contains("æ„¿æ™¯") || query_lower.contains("æœªæ¥") || query_lower.contains("è§„åˆ’") { 
            emotion |= Self::EMOTION_ANTICIPATION; 
        }

        // Mock Type Inference
        if query_lower.contains("pero") || query_lower.contains("ç”¨æˆ·") || query_lower.contains("å¥³å­©") {
            type_val = Self::TYPE_PERSON;
        } else if query_lower.contains("rust") || query_lower.contains("ä»£ç ") || query_lower.contains("ç®—æ³•") {
            type_val = Self::TYPE_TECH;
        } else if query_lower.contains("äº‹æƒ…") || query_lower.contains("å‘ç”Ÿ") {
            type_val = Self::TYPE_EVENT;
        } else if query_lower.contains("è´è¶ç»“") || query_lower.contains("é”®ç›˜") {
            type_val = Self::TYPE_OBJECT;
        }

        Self::compute_multimodal(&query_lower, timestamp, emotion, type_val)
    }

    /// ä¼ ç»Ÿçš„ SimHash è®¡ç®— (ä»…ç”¨äºè¯­ä¹‰åŒºï¼Œå‹ç¼©åˆ° 32 ä½)
    pub fn compute_text_hash_32(text: &str) -> u32 {
        let text_lower = text.to_lowercase();
        let mut v = [0i32; 32];
        
        for word in text_lower.split_whitespace() {
            Self::update_v_32(&mut v, word);
        }
        // å¤„ç†ä¸­æ–‡ç­‰æ— ç©ºæ ¼å­—ç¬¦
        for c in text_lower.chars() {
            let mut buf = [0u8; 4];
            let s = c.encode_utf8(&mut buf);
            Self::update_v_32(&mut v, s);
        }

        let mut finger_print = 0u32;
        for i in 0..32 {
            if v[i] > 0 {
                finger_print |= 1 << i;
            }
        }
        finger_print
    }

    /// å…¼å®¹æ—§ç‰ˆæ¥å£ (ä»…è®¡ç®—æ–‡æœ¬ï¼Œå…¶ä»–é»˜è®¤ä¸º 0)
    pub fn compute(text: &str) -> u64 {
        Self::compute_multimodal(text, 0, 0, 0)
    }

    fn update_v_32(v: &mut [i32; 32], token: &str) {
        let mut hasher = XxHash64::with_seed(0);
        token.hash(&mut hasher);
        let hash = hasher.finish();
        
        for i in 0..32 {
            let bit = (hash >> i) & 1;
            if bit == 1 {
                v[i] += 1;
            } else {
                v[i] -= 1;
            }
        }
    }

    fn compute_temporal_hash(timestamp: u64) -> u16 {
        // çº¯æ—¶é—´æˆ³å“ˆå¸Œ
        let mut hasher = XxHash64::with_seed(12345); // ç‹¬ç«‹ Seed
        timestamp.hash(&mut hasher);
        let h = hasher.finish();
        (h & 0xFFFF) as u16
    }

    /// è®¡ç®—åŠ æƒæ±‰æ˜è·ç¦»ç›¸ä¼¼åº¦ (V2: æ”¯æŒåˆ†åŒºæƒé‡æ©ç )
    /// mask: ç”¨äºæŒ‡å®šåªå…³æ³¨å“ªäº›åŒºåŸŸ (ä¾‹å¦‚åªå…³æ³¨æ—¶ç©ºåŒº)
    pub fn similarity_weighted(a: u64, b: u64, mask: u64) -> f32 {
        let xor = (a ^ b) & mask;
        let dist = xor.count_ones();
        let total_bits = mask.count_ones();
        if total_bits == 0 { return 0.0; }
        1.0 - (dist as f32 / total_bits as f32)
    }
    
    /// åŸå§‹ç›¸ä¼¼åº¦æ¥å£
    pub fn similarity(a: u64, b: u64) -> f32 {
        // é»˜è®¤å…¨åŒºåŒ¹é…
        Self::similarity_weighted(a, b, 0xFFFFFFFFFFFFFFFF)
    }
}

// ============================================================================
// 2. æ ¸å¿ƒæ•°æ®ç»“æ„
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum NodeType {
    Feature, // ç‰¹å¾é”šç‚¹ï¼ˆå…³é”®è¯ã€å®ä½“ï¼‰
    Event,   // äº‹ä»¶æ€»ç»“èŠ‚ç‚¹ï¼ˆè®°å¿†ä¸»ä½“ï¼‰
}

#[derive(Clone, Debug)]
pub struct GraphEdge {
    pub target_node_id: i64,
    pub connection_strength: u16,
    pub edge_type: u8, // V2: 0=Assoc, 1=Cause, 2=Seq, 3=Contrast
}

pub struct Node {
    pub id: i64,
    pub node_type: NodeType,
    pub content: String,       // å¯¹äº Event æ˜¯æ€»ç»“ï¼Œå¯¹äº Feature æ˜¯å…³é”®è¯
    pub fingerprint: u64,      // è¯­ä¹‰æŒ‡çº¹
    
    // V2 New Fields
    pub timestamp: u64,        // Unix æ—¶é—´æˆ³
    pub emotions: SmallVec<[u8; 8]>, // æƒ…æ„ŸçŸ¢é‡ (8ç»´)
    pub prev_event: Option<i64>,     // æ—¶åºå‰é©±
    pub next_event: Option<i64>,     // æ—¶åºåç»§
}

// ============================================================================
// 3. é«˜çº§å®éªŒå¼•æ“
// ============================================================================

pub struct ChaosStore {
    pub ids: Vec<i64>,
    pub fingerprints: Vec<u128>,
    pub vectors: Vec<Vec<f16>>,
    pub id_to_index: AHashMap<i64, usize>,
}

impl ChaosStore {
    pub fn new() -> Self {
        Self {
            ids: Vec::new(),
            fingerprints: Vec::new(),
            vectors: Vec::new(),
            id_to_index: AHashMap::new(),
        }
    }

    pub fn add(&mut self, id: i64, fp: u128, vec: Vec<f16>) {
        if !self.id_to_index.contains_key(&id) {
            let idx = self.ids.len();
            self.ids.push(id);
            self.fingerprints.push(fp);
            self.vectors.push(vec);
            self.id_to_index.insert(id, idx);
        }
    }
}

pub trait AsyncTaskInterface {
    fn schedule_maintenance(&self, context: &str);
}

pub struct MockAsyncTask;
impl AsyncTaskInterface for MockAsyncTask {
    fn schedule_maintenance(&self, _context: &str) {
        // Placeholder
    }
}

pub struct AdvancedEngine {
    pub nodes: AHashMap<i64, Node>,
    pub chaos_store: ChaosStore,
    pub graph: AHashMap<i64, SmallVec<[GraphEdge; 4]>>,
    
    // ç¬¬ä¸€å¥—æ•°æ®åº“ï¼šå®šä¹‰åº“ (Ontology)
    pub ontology_graph: AHashMap<i64, SmallVec<[GraphEdge; 4]>>,
    
    // æœç´¢è¾…åŠ©
    pub ac_matcher: Option<AhoCorasick>,
    pub feature_keywords: Vec<String>,
    pub keyword_to_node: AHashMap<String, i64>,
    
    // V2: æ€§èƒ½æ§åˆ¶
    pub in_degrees: AHashMap<i64, u32>, // é¢„è®¡ç®—å…¥åº¦
    
    // V2: æ—¶ç©ºç´¢å¼• (Temporal Index) - ç”¨äºå¿«é€Ÿå…±æŒ¯å¬å›
    pub temporal_index: AHashMap<u16, Vec<i64>>,
    
    // V2: æƒ…æ„Ÿç´¢å¼• (Affective Index) - ç”¨äºæƒ…æ„Ÿå…±æŒ¯
    pub affective_index: AHashMap<u8, Vec<i64>>,

    // V2: å¼‚æ­¥æ¥å£
    pub async_task: Box<dyn AsyncTaskInterface + Send + Sync>,

    // Phase 4: Static Embedding Model
    pub embedding_model: Option<StaticModel>,
}

#[wasm_bindgen]
pub struct PedsaEngine {
    inner: AdvancedEngine,
}

#[wasm_bindgen]
impl PedsaEngine {
    #[wasm_bindgen(constructor)]
    pub fn new() -> Self {
        console_error_panic_hook::set_once();
        Self {
            inner: AdvancedEngine::new()
        }
    }

    pub fn load_model_from_bytes(&mut self, data: &[u8]) -> Result<(), JsValue> {
        let model = StaticModel::load_from_bytes(data)
            .map_err(|e| JsValue::from_str(&e.to_string()))?;
        self.inner.embedding_model = Some(model);
        Ok(())
    }

    pub fn add_feature(&mut self, id: i64, keyword: &str) {
        self.inner.add_feature(id, keyword);
    }

    pub fn add_event(&mut self, id: i64, summary: &str) {
        // Simple wrapper without chaos for now
        self.inner.add_event(id, summary, None, None);
    }

    pub fn add_edge(&mut self, src: i64, tgt: i64, weight: f32) {
        self.inner.add_edge(src, tgt, weight);
    }

    pub fn maintain_ontology(&mut self, source: &str, target: &str, relation_type: &str, strength: f32) {
        self.inner.maintain_ontology(source, target, relation_type, strength);
    }

    pub fn compile(&mut self) {
        self.inner.compile();
    }

    pub fn prune_ontology(&mut self) {
        self.inner.prune_ontology();
    }

    /// Returns JSON string of results with content
    pub fn retrieve(&self, query: &str, ref_time: u64, chaos_level: f32) -> String {
        let results = self.inner.retrieve(query, ref_time, chaos_level);
        // Manual JSON serialization to avoid serde overhead for now
        let mut json = String::from("[");
        for (i, (id, score)) in results.iter().enumerate() {
            if i > 0 { json.push(','); }
            let node_opt = self.inner.nodes.get(id);
            let content = node_opt.map(|n| n.content.as_str()).unwrap_or("");
            let timestamp = node_opt.map(|n| n.timestamp).unwrap_or(0);
            
            // Escape quotes in content for JSON
            let escaped_content = content.replace("\"", "\\\"");
            json.push_str(&format!("{{\"id\":{},\"score\":{:.4},\"content\":\"{}\",\"timestamp\":{}}}", id, score, escaped_content, timestamp));
        }
        json.push(']');
        json
    }
}

impl AdvancedEngine {
    pub fn new() -> Self {
        Self {
            nodes: AHashMap::new(),
            chaos_store: ChaosStore::new(),
            graph: AHashMap::new(),
            ontology_graph: AHashMap::new(),
            ac_matcher: None,
            feature_keywords: Vec::new(),
            keyword_to_node: AHashMap::new(),
            in_degrees: AHashMap::new(),
            temporal_index: AHashMap::new(),
            affective_index: AHashMap::new(),
            async_task: Box::new(MockAsyncTask),
            embedding_model: None,
        }
    }

    /// æ·»åŠ ç‰¹å¾èŠ‚ç‚¹
    pub fn add_feature(&mut self, id: i64, keyword: &str) {
        let keyword_lower = keyword.to_lowercase();
        
        // --- åœç”¨è¯ç¡¬è¿‡æ»¤ (åŒä¿é™©æœºåˆ¶) ---
        // åŒ…å«ä¸­è‹±æ–‡å¸¸è§çš„è™šè¯ã€ä»‹è¯ã€ä»£è¯ã€åŠ©åŠ¨è¯åŠè¿è¯
        let stopwords = [
            // ä¸­æ–‡è™šè¯
            "çš„", "æ˜¯", "äº†", "åœ¨", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "è¿™", "é‚£", "éƒ½", "å’Œ", "å¹¶", "ä¸”",
            "ä¹Ÿ", "å°±", "ç€", "å§", "å—", "å‘¢", "å•Š", "å‘€", "å‘œ", "å“", "å“¼", "å‘¸", "å–½",
            // English Prepositions
            "a", "an", "the", "about", "above", "across", "after", "against", "along", "among", "around", "at", 
            "before", "behind", "below", "beneath", "beside", "between", "beyond", "but", "by", "despite", "down", 
            "during", "except", "for", "from", "in", "inside", "into", "like", "near", "of", "off", "on", "onto", 
            "out", "outside", "over", "past", "since", "through", "throughout", "till", "to", "toward", "under", 
            "underneath", "until", "up", "upon", "with", "within", "without",
            // English Pronouns
            "i", "me", "my", "mine", "we", "us", "our", "ours", "you", "your", "yours", "he", "him", "his", 
            "she", "her", "hers", "it", "its", "they", "them", "their", "theirs", "this", "that", "these", "those", 
            "who", "whom", "whose", "which", "what", "each", "every", "either", "neither", "some", "any", "no", 
            "none", "both", "few", "many", "other", "another",
            // English Auxiliaries
            "am", "is", "are", "was", "were", "be", "being", "been", "have", "has", "had", "do", "does", "did", 
            "shall", "will", "should", "would", "may", "might", "must", "can", "could",
            // English Conjunctions & Others
            "and", "or", "so", "nor", "yet", "although", "because", "unless", "while", "where", "when", "how", "whether"
        ];
        if stopwords.contains(&keyword_lower.as_str()) {
            return;
        }

        let node = Node {
            id,
            node_type: NodeType::Feature,
            content: keyword_lower.clone(),
            fingerprint: SimHash::compute(&keyword_lower),
            timestamp: 0,
            emotions: SmallVec::new(),
            prev_event: None,
            next_event: None,
        };
        self.nodes.insert(id, node);
        self.feature_keywords.push(keyword_lower.clone());
        self.keyword_to_node.insert(keyword_lower, id);
    }

    /// è¾…åŠ©ï¼šä»æ–‡æœ¬ä¸­æå–æ—¥æœŸå¹¶è½¬æ¢ä¸ºæ—¶é—´æˆ³ (YYYYå¹´MMæœˆDDæ—¥)
    fn extract_timestamp(text: &str) -> u64 {
        // ç®€æ˜“è§£æå™¨ï¼ŒæŸ¥æ‰¾ "20xxå¹´xxæœˆxxæ—¥"
        // é»˜è®¤åŸºå‡†æ—¶é—´ï¼š2023-01-01 (1672531200)
        let default_ts = 1672531200;
        
        // éå†æ‰€æœ‰ "å¹´" çš„å‡ºç°ä½ç½®
        for (year_idx, _) in text.match_indices("å¹´") {
            if year_idx >= 4 && text.is_char_boundary(year_idx - 4) {
                if let Ok(year) = text[year_idx-4..year_idx].parse::<i32>() {
                    let mut day = 1;
                    
                    let rest = &text[year_idx+3..]; // è·³è¿‡ "å¹´" (UTF-8 3 bytes)
                    
                    // æŸ¥æ‰¾ "æœˆ"ï¼Œä¸”è·ç¦»ä¸åº”å¤ªè¿œ (æœ€å¤š 5 å­—èŠ‚ï¼Œå®¹çº³ " 12" æˆ– "1")
                    if let Some(month_idx) = rest.find("æœˆ") {
                        if month_idx <= 5 {
                            let m_str = rest[..month_idx].trim();
                            if let Ok(month) = m_str.parse::<i32>() {
                                
                                let rest_day = &rest[month_idx+3..];
                                // æŸ¥æ‰¾ "æ—¥"ï¼Œè·ç¦»ä¹Ÿä¸åº”å¤ªè¿œ
                                if let Some(day_idx) = rest_day.find("æ—¥") {
                                    if day_idx <= 5 {
                                        let d_str = rest_day[..day_idx].trim();
                                        if let Ok(d) = d_str.parse::<i32>() {
                                            day = d;
                                        }
                                    }
                                }
                                
                                // ç®€å•è½¬ä¸º Unix Timestamp
                                let ts = (year as u64 - 1970) * 31536000 + (month as u64) * 2592000 + (day as u64) * 86400;
                                return ts;
                            }
                        }
                    }
                }
            }
        }
        default_ts
    }

    /// æ··æ²Œå‘é‡åŒ–æ¥å£ï¼šå°†æ–‡æœ¬è‡ªåŠ¨è½¬æ¢ä¸º 128 ç»´ f16 å‘é‡å’Œ 1-bit u128 æŒ‡çº¹
    pub fn calculate_chaos(&self, text: &str) -> Option<(u128, Vec<f16>)> {
        let model = self.embedding_model.as_ref()?;
        
        let mut weighted_ranges = Vec::new();
        if let Some(matcher) = &self.ac_matcher {
            for mat in matcher.find_iter(&text.to_lowercase()) {
                weighted_ranges.push((mat.start(), mat.end(), 5.0));
            }
        }

        if let Some(vec_f32) = model.vectorize_weighted(text, &weighted_ranges) {
            let chaos_vector: Vec<f16> = vec_f32.iter().map(|&x| f16::from_f32(x)).collect();
            let chaos_fingerprint = SimHash::quantize_vector(&chaos_vector);
            Some((chaos_fingerprint, chaos_vector))
        } else {
            None
        }
    }

    /// æ·»åŠ äº‹ä»¶èŠ‚ç‚¹
    pub fn add_event(&mut self, id: i64, summary: &str, chaos_fp: Option<u128>, chaos_vec: Option<Vec<f16>>) {
        // è‡ªåŠ¨æå–æ—¶é—´æˆ³
        let timestamp = Self::extract_timestamp(summary);

        // V2: åœ¨å…¥åº“æ—¶è‡ªåŠ¨è¿›è¡Œæ—¶ç©º/æƒ…æ„Ÿç‰¹å¾æå– (Auto-Tagging)
        // ä½¿ç”¨æå–åˆ°çš„ç»å¯¹æ—¶é—´æˆ³æ¥è®¡ç®—åˆå§‹æŒ‡çº¹
        let fingerprint = SimHash::compute_multimodal(summary, timestamp, 0, 0);

        // V3 Phase 4: Auto Vectorization (Chaos Vector)
        let mut chaos_fingerprint = chaos_fp.unwrap_or(0u128);
        let mut chaos_vector = chaos_vec.unwrap_or_default();

        if chaos_fingerprint == 0 && chaos_vector.is_empty() {
            if let Some((fp, vec)) = self.calculate_chaos(summary) {
                chaos_fingerprint = fp;
                chaos_vector = vec;
            }
        }
        
        let node = Node {
            id,
            node_type: NodeType::Event,
            content: summary.to_string(),
            fingerprint,
            timestamp, 
            emotions: SmallVec::new(),
            prev_event: None,
            next_event: None,
        };
        self.nodes.insert(id, node);
        
        // SoA Storage
        if chaos_fingerprint != 0 || !chaos_vector.is_empty() {
             self.chaos_store.add(id, chaos_fingerprint, chaos_vector);
        }

        // V2: æ›´æ–°å€’æ’ç´¢å¼• (Inverted Indexes) ç”¨äºå¿«é€Ÿå¬å›
        // 1. æ—¶ç©ºç´¢å¼•
        if (fingerprint & SimHash::MASK_TEMPORAL) != 0 {
            let st_hash = ((fingerprint & SimHash::MASK_TEMPORAL) >> 32) as u16;
            self.temporal_index.entry(st_hash).or_default().push(id);
        }

        // 2. æƒ…æ„Ÿç´¢å¼•
        if (fingerprint & SimHash::MASK_AFFECTIVE) != 0 {
            let emotion_hash = ((fingerprint & SimHash::MASK_AFFECTIVE) >> 48) as u8;
            for i in 0..8 {
                if (emotion_hash & (1 << i)) != 0 {
                    self.affective_index.entry(1 << i).or_default().push(id);
                }
            }
        }
    }

    /// å»ºç«‹å…³è” (V2: å¢åŠ é‡å¤è¾¹æ£€æµ‹ä¸å¼ºåº¦æ›´æ–°é€»è¾‘)
    pub fn add_edge(&mut self, src: i64, tgt: i64, weight: f32) {
        let quantized = (weight.clamp(0.0, 1.0) * 65535.0) as u16;
        let edges = self.graph.entry(src).or_default();
        
        if let Some(edge) = edges.iter_mut().find(|e| e.target_node_id == tgt) {
            // å¦‚æœè¾¹å·²å­˜åœ¨ï¼Œæ›´æ–°ä¸ºè¾ƒå¤§çš„å¼ºåº¦å€¼ (æ¨¡æ‹Ÿè®°å¿†å¢å¼º)
            if quantized > edge.connection_strength {
                edge.connection_strength = quantized;
            }
        } else {
            edges.push(GraphEdge {
                target_node_id: tgt,
                connection_strength: quantized,
                edge_type: 0,
            });
        }
    }

    /// æ·»åŠ å®šä¹‰åº“å…³è” (ç¬¬ä¸€å¥—æ•°æ®åº“)
    /// is_equality: æ˜¯å¦ä¸ºç­‰ä»·å…³ç³» (Type 3)
    /// is_inhibition: æ˜¯å¦ä¸ºæŠ‘åˆ¶å…³ç³» (Type 255)
    pub fn add_ontology_edge(&mut self, src_word: &str, tgt_word: &str, weight: f32, is_equality: bool, is_inhibition: bool) {
        let src = self.get_or_create_feature(src_word);
        let tgt = self.get_or_create_feature(tgt_word);
        
        if src == -1 || tgt == -1 {
            return; // å±è”½è¯ä¸å»ºç«‹å…³è”
        }
        
        let quantized = (weight.clamp(0.0, 1.0) * 65535.0) as u16;
        
        // ç¡®å®šè¾¹ç±»å‹ (ç®€åŒ–ä¸ºä¸‰ç§æ ¸å¿ƒé€»è¾‘)
        let edge_type = if is_equality {
            SimHash::EDGE_EQUALITY
        } else if is_inhibition {
            SimHash::EDGE_INHIBITION
        } else {
            SimHash::EDGE_REPRESENTATION
        };

        // å¤„ç†æ­£å‘è¾¹
        {
            let edges = self.ontology_graph.entry(src).or_default();
            if let Some(edge) = edges.iter_mut().find(|e| e.target_node_id == tgt) {
                // [LTD æœºåˆ¶] è¢«åŠ¨å¼ºåŒ– (Hebbian Learning)
                edge.connection_strength = edge.connection_strength.saturating_add(quantized / 2).max(quantized);
                // æ›´æ–°ç±»å‹
                edge.edge_type = edge_type;
            } else {
                edges.push(GraphEdge {
                    target_node_id: tgt,
                    connection_strength: quantized,
                    edge_type,
                });
            }
        }
        
        // å¤„ç†åå‘è¾¹
        // 1. Equality (Type 1): å¼ºåˆ¶åŒå‘ï¼Œè¡¨ç¤º A==B ä¸” B==A
        // 2. Inhibition (Type 255): å¼ºåˆ¶åŒå‘ï¼Œè¡¨ç¤º Aäº’æ–¥B ä¸” Bäº’æ–¥A
        // 3. Representation (Type 0): é»˜è®¤å•å‘ (Directed)ï¼Œå› ä¸º"çœ‹åˆ°Bæƒ³åˆ°A"ä¸ä»£è¡¨"çœ‹åˆ°Aä¸€å®šæƒ³åˆ°B"
        //    (é™¤éä¸šåŠ¡å±‚æ˜¾å¼è¦æ±‚åŒå‘ï¼Œå¦åˆ™åº•å±‚åªå­˜å•å‘)
        if edge_type == SimHash::EDGE_EQUALITY || edge_type == SimHash::EDGE_INHIBITION {
            let rev_edges = self.ontology_graph.entry(tgt).or_default();
            if let Some(edge) = rev_edges.iter_mut().find(|e| e.target_node_id == src) {
                // [LTD æœºåˆ¶] è¢«åŠ¨å¼ºåŒ–
                edge.connection_strength = edge.connection_strength.saturating_add(quantized / 2).max(quantized);
                edge.edge_type = edge_type;
            } else {
                rev_edges.push(GraphEdge {
                    target_node_id: src,
                    connection_strength: quantized,
                    edge_type,
                });
            }
        }
    }

    // ========================================================================
    // åŠ¨æ€å‰ªæ (LTD: Long-Term Depression)
    // ========================================================================

    /// æ‰§è¡Œå…¨å±€è¡°å‡ä¸ç‰©ç†å‰ªæ
    /// decay_rate: è¡°å‡æ¯”ç‡ (0.0 - 1.0)ï¼Œå»ºè®® 0.95
    /// threshold: å‰ªæé˜ˆå€¼ (0 - 65535)ï¼Œå»ºè®® 3276 (0.05)
    pub fn apply_global_decay_and_pruning(&mut self, decay_rate: f32, threshold: u16) -> usize {
        let mut pruned_count = 0;
        
        // éå†æ•´ä¸ª Ontology å›¾è°±
        for edges in self.ontology_graph.values_mut() {
            // 1. å…¨å±€ç†µå¢ (Entropy Increase)
            for edge in edges.iter_mut() {
                let current = edge.connection_strength as f32;
                edge.connection_strength = (current * decay_rate) as u16;
            }
            
            // 2. ç‰©ç†æ–­è£‚ (Pruning)
            let before_len = edges.len();
            edges.retain(|e| e.connection_strength > threshold);
            let after_len = edges.len();
            
            pruned_count += before_len - after_len;
        }
        
        if pruned_count > 0 {
            println!("[PEDSA Memory] Pruning executed: {} synapses disconnected.", pruned_count);
        }
        
        pruned_count
    }

    fn get_or_create_feature(&mut self, word: &str) -> i64 {
        let word_lower = word.to_lowercase();
        
        // åœç”¨è¯æ£€æŸ¥ (åŒæ­¥ add_feature ä¸­çš„åˆ—è¡¨)
        let stopwords = [
            // ä¸­æ–‡è™šè¯
            "çš„", "æ˜¯", "äº†", "åœ¨", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "è¿™", "é‚£", "éƒ½", "å’Œ", "å¹¶", "ä¸”",
            "ä¹Ÿ", "å°±", "ç€", "å§", "å—", "å‘¢", "å•Š", "å‘€", "å‘œ", "å“", "å“¼", "å‘¸", "å–½",
            // English Prepositions
            "a", "an", "the", "about", "above", "across", "after", "against", "along", "among", "around", "at", 
            "before", "behind", "below", "beneath", "beside", "between", "beyond", "but", "by", "despite", "down", 
            "during", "except", "for", "from", "in", "inside", "into", "like", "near", "of", "off", "on", "onto", 
            "out", "outside", "over", "past", "since", "through", "throughout", "till", "to", "toward", "under", 
            "underneath", "until", "up", "upon", "with", "within", "without",
            // English Pronouns
            "i", "me", "my", "mine", "we", "us", "our", "ours", "you", "your", "yours", "he", "him", "his", 
            "she", "her", "hers", "it", "its", "they", "them", "their", "theirs", "this", "that", "these", "those", 
            "who", "whom", "whose", "which", "what", "each", "every", "either", "neither", "some", "any", "no", 
            "none", "both", "few", "many", "other", "another",
            // English Auxiliaries
            "am", "is", "are", "was", "were", "be", "being", "been", "have", "has", "had", "do", "does", "did", 
            "shall", "will", "should", "would", "may", "might", "must", "can", "could",
            // English Conjunctions & Others
            "and", "or", "so", "nor", "yet", "although", "because", "unless", "while", "where", "when", "how", "whether"
        ];
        if stopwords.contains(&word_lower.as_str()) {
            return -1; // è¿”å›éæ³• ID è¡¨ç¤ºè¯¥è¯è¢«å±è”½
        }

        if let Some(&id) = self.keyword_to_node.get(&word_lower) {
            id
        } else {
            let mut s = XxHash64::with_seed(0);
            word_lower.hash(&mut s);
            let id = (s.finish() as i64).abs();
            self.add_feature(id, &word_lower);
            id
        }
    }

    /// å»ºç«‹åŒå‘æ—¶åºé“¾è¡¨ (Temporal Backbone)
    pub fn build_temporal_backbone(&mut self) {
        println!("â³ æ­£åœ¨æ„å»ºæ—¶åºè„Šæ¢ (Temporal Backbone)...");
        
        // 1. æ”¶é›†æ‰€æœ‰ Event èŠ‚ç‚¹å¹¶æŒ‰æ—¶é—´æˆ³æ’åº
        let mut events: Vec<(i64, u64)> = self.nodes.values()
            .filter(|n| n.node_type == NodeType::Event)
            .map(|n| (n.id, n.timestamp))
            .collect();
        
        // å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œæš‚æ—¶ç”¨ ID æ¨¡æ‹Ÿé¡ºåºï¼ˆä»…ä¾›æµ‹è¯•ï¼‰
        // åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œtimestamp åº”è¯¥æ˜¯å¿…å¡«çš„
        events.sort_by(|a, b| {
            if a.1 != b.1 {
                a.1.cmp(&b.1)
            } else {
                a.0.cmp(&b.0) // æ—¶é—´æˆ³ç›¸åŒåˆ™æŒ‰ ID æ’åº
            }
        });

        // 2. ä¸²è”åŒå‘é“¾è¡¨
        for i in 0..events.len() {
            let (curr_id, _) = events[i];
            
            if i > 0 {
                let (prev_id, _) = events[i-1];
                if let Some(node) = self.nodes.get_mut(&curr_id) {
                    node.prev_event = Some(prev_id);
                }
            }
            
            if i < events.len() - 1 {
                let (next_id, _) = events[i+1];
                if let Some(node) = self.nodes.get_mut(&curr_id) {
                    node.next_event = Some(next_id);
                }
            }
        }
        println!("âœ… æ—¶åºè„Šæ¢æ„å»ºå®Œæˆï¼Œå·²ä¸²è” {} ä¸ªäº‹ä»¶èŠ‚ç‚¹ã€‚", events.len());
    }

    // Data loading functions removed for WASM core


    /// ç¼–è¯‘ AC è‡ªåŠ¨æœº
    pub fn compile(&mut self) {
        // åªå¯¹ Feature èŠ‚ç‚¹ç¼–è¯‘ AC è‡ªåŠ¨æœº
        let mut keywords: Vec<_> = self.nodes.values()
            .filter(|n| n.node_type == NodeType::Feature)
            .map(|n| n.content.clone())
            .collect();
        
        // V2: å…³é”®ä¼˜åŒ– - æŒ‰é•¿åº¦é™åºæ’åºï¼Œç¡®ä¿ä¼˜å…ˆåŒ¹é…é•¿è¯ (å¦‚ "åˆ†å¸ƒå¼ç¼–è¯‘" ä¼˜äº "åˆ†å¸ƒå¼")
        keywords.sort_by(|a, b| b.len().cmp(&a.len()));

        if !keywords.is_empty() {
            self.ac_matcher = Some(AhoCorasickBuilder::new()
                .match_kind(MatchKind::LeftmostLongest)
                .build(&keywords)
                .unwrap());
            self.feature_keywords = keywords;
        }

        // V2: è®¡ç®—èŠ‚ç‚¹å…¥åº¦ (In-degree) ä»¥ç”¨äºåå‘æŠ‘åˆ¶
        self.in_degrees.clear();
        // ç»Ÿè®¡ Memory Graph
        for edges in self.graph.values() {
            for edge in edges {
                *self.in_degrees.entry(edge.target_node_id).or_default() += 1;
            }
        }
        // ç»Ÿè®¡ Ontology Graph
        for edges in self.ontology_graph.values() {
            for edge in edges {
                *self.in_degrees.entry(edge.target_node_id).or_default() += 1;
            }
        }

        // V2: æ„å»ºæ—¶ç©ºç´¢å¼• (Spatio-Temporal Index) ä¸ æƒ…æ„Ÿç´¢å¼• (Affective Index)
        self.temporal_index.clear();
        self.affective_index.clear();

        for node in self.nodes.values() {
            if node.node_type == NodeType::Event {
                // æ—¶ç©ºç´¢å¼•
                let st_hash = ((node.fingerprint & SimHash::MASK_TEMPORAL) >> 32) as u16;
                if st_hash != 0 {
                    self.temporal_index.entry(st_hash).or_default().push(node.id);
                }

                // æƒ…æ„Ÿç´¢å¼•
                let emotion_hash = ((node.fingerprint & SimHash::MASK_AFFECTIVE) >> 48) as u8;
                if emotion_hash != 0 {
                    // å¯¹äºæ¯ä¸ªè®¾ç½®äº†çš„ä½ï¼Œéƒ½åŠ å…¥åˆ°å¯¹åº”çš„ç´¢å¼•æ¡¶ä¸­ (æ”¯æŒæ··åˆæƒ…æ„Ÿ)
                    for i in 0..8 {
                        if (emotion_hash & (1 << i)) != 0 {
                            self.affective_index.entry(1 << i).or_default().push(node.id);
                        }
                    }
                }
            }
        }

        println!("ğŸš€ å¼•æ“ç¼–è¯‘å®Œæˆï¼š{} ä¸ªç‰¹å¾é”šç‚¹, {} ä¸ªæ€»èŠ‚ç‚¹, {} ä¸ªæ—¶ç©ºæ¡¶, {} ä¸ªæƒ…æ„Ÿç»´åº¦", 
            self.feature_keywords.len(), self.nodes.len(), self.temporal_index.len(), self.affective_index.len());
    }

    // Test data generation removed

    /// æ‰§è¡Œå¤šçº§æ£€ç´¢ (V2: å¢åŠ èƒ½é‡æ§åˆ¶æœºåˆ¶ + åˆ†åŒºæ—¶ç©ºå…±æŒ¯)
    /// ç¬¬å››é˜¶æ®µï¼šåŒè½¨æ£€ç´¢ï¼ˆç†æ€§ + æ··æ²Œï¼‰
    /// 
    /// # å‚æ•°
    /// * `query` - æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚
    /// * `ref_time` - ç”¨äºç›¸å¯¹æ—¶é—´è§£æçš„å‚è€ƒæ—¶é—´æˆ³ã€‚
    /// * `chaos_level` - 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚
    ///   - 0.0: çº¯ç†æ€§æ£€ç´¢ï¼ˆç¡®å®šæ€§ï¼‰ã€‚
    ///   - 1.0: çº¯æ··æ²Œæ£€ç´¢ï¼ˆé«˜éšæœºæ€§/åˆ›é€ æ€§ï¼‰ã€‚
    ///   - ä¸­é—´å€¼åˆ™æ··åˆä¸¤è€…çš„å¾—åˆ†ã€‚
    pub fn retrieve(&self, query: &str, ref_time: u64, chaos_level: f32) -> Vec<(i64, f32)> {
        let mut activated_keywords = AHashMap::new();
        let query_lower = query.to_lowercase();
        // V2: ä½¿ç”¨æ™ºèƒ½æŒ‡çº¹ç”Ÿæˆï¼Œæå–æ—¶ç©º/æƒ…æ„Ÿç‰¹å¾
        // ä¼ å…¥ ref_time ä»¥æ”¯æŒç›¸å¯¹æ—¶é—´è§£æ
        let query_fp = SimHash::compute_for_query(&query_lower, ref_time);

        // --- Step 1: ç‰¹å¾å…±æŒ¯ (AC Matcher) - æå¿« ---
        if let Some(matcher) = &self.ac_matcher {
            for mat in matcher.find_iter(&query_lower) {
                let kw = &self.feature_keywords[mat.pattern()];
                if let Some(&node_id) = self.keyword_to_node.get(kw) {
                    activated_keywords.insert(node_id, 1.0);
                }
            }
        }

        // --- Step 1.5: æ—¶é—´å…±æŒ¯ (Temporal Resonance) ---
        // å¦‚æœ Query åŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œç›´æ¥ä»ç´¢å¼•ä¸­å¬å›å€™é€‰èŠ‚ç‚¹ (Bypass Semantic Matching)
        if (query_fp & SimHash::MASK_TEMPORAL) != 0 {
            let st_hash = ((query_fp & SimHash::MASK_TEMPORAL) >> 32) as u16;
            if let Some(candidates) = self.temporal_index.get(&st_hash) {
                // å°†è¿™äº›å€™é€‰èŠ‚ç‚¹åŠ å…¥åˆå§‹æ¿€æ´»é›†åˆ
                // æ³¨æ„ï¼šè¿™äº›é€šå¸¸æ˜¯ Event èŠ‚ç‚¹ï¼Œå®ƒä»¬å°†ç›´æ¥ä½œä¸ºç§å­è¿›å…¥åç»­æµç¨‹
                for &id in candidates {
                    let entry = activated_keywords.entry(id).or_insert(0.0);
                    // åˆå§‹å…±æŒ¯èƒ½é‡è®¾ä¸º 0.6 (ä½äºå®Œå…¨åŒ¹é…çš„ 1.0)
                    if *entry < 0.6 { *entry = 0.6; }
                }
            }
        }

        // --- Step 1.6: æƒ…æ„Ÿå…±æŒ¯ (Affective Resonance) ---
        // å¦‚æœ Query åŒ…å«æƒ…æ„Ÿä¿¡æ¯ï¼Œä»æƒ…æ„Ÿç´¢å¼•ä¸­å¬å›å€™é€‰èŠ‚ç‚¹
        if (query_fp & SimHash::MASK_AFFECTIVE) != 0 {
            let emotion_hash = ((query_fp & SimHash::MASK_AFFECTIVE) >> 48) as u8;
            for i in 0..8 {
                if (emotion_hash & (1 << i)) != 0 {
                    if let Some(candidates) = self.affective_index.get(&(1 << i)) {
                         for &id in candidates {
                            let entry = activated_keywords.entry(id).or_insert(0.0);
                            // æƒ…æ„Ÿå…±æŒ¯èƒ½é‡è®¾ä¸º 0.7 (æ¯”è¾ƒå¼ºçƒˆï¼Œå› ä¸ºæ˜¯å†…å¿ƒçš„ç›´æ¥æŠ•å°„)
                            if *entry < 0.7 { *entry = 0.7; }
                        }
                    }
                }
            }
        }

        // --- Step 2: ç¬¬ä¸€æ•°æ®åº“ (Ontology å®šä¹‰åº“) æ‰©æ•£ ---
        let mut ontology_expanded = activated_keywords.clone();
        for (&node_id, &score) in &activated_keywords {
            if let Some(neighbors) = self.ontology_graph.get(&node_id) {
                for edge in neighbors {
                    let weight = edge.connection_strength as f32 / 65535.0;
                    
                    // V2: åå‘æŠ‘åˆ¶ (Inverse Inhibition) - é™ä½æ³›åŒ–è¯æƒé‡
                    let degree = self.in_degrees.get(&edge.target_node_id).unwrap_or(&1);
                    // log10(1)=0 -> 1.0; log10(10)=1 -> 0.5; log10(100)=2 -> 0.33
                    let inhibition_factor = 1.0 / (1.0 + (*degree as f32).log10()); 
                    
                    // V3.5: Typed Edge Logic
                    // 1. EQUALITY (1): é›¶æŸè€—ï¼Œæ— è§†åå‘æŠ‘åˆ¶ï¼Œèƒ½é‡ç›´æ¥ä¼ é€’ (max)
                    // 2. INHIBITION (255): è´Ÿèƒ½é‡æ‰£å‡
                    // 3. REPRESENTATION (0): æ­£å¸¸è¡°å‡
                    
                    if edge.edge_type == SimHash::EDGE_EQUALITY {
                        // ç­‰ä»·ä¼ é€’ï¼šç›´æ¥å–æºèŠ‚ç‚¹èƒ½é‡ï¼Œä¸æ‰“æŠ˜
                        let entry = ontology_expanded.entry(edge.target_node_id).or_insert(0.0);
                        if score > *entry {
                             *entry = score;
                        }
                        continue;
                    }
                    
                    // è®¡ç®—åŸºç¡€èƒ½é‡ (å«æƒé‡å’Œåå‘æŠ‘åˆ¶)
                    let energy = score * weight * 0.95 * inhibition_factor;
                    
                    if edge.edge_type == SimHash::EDGE_INHIBITION {
                        // æŠ‘åˆ¶ä¼ é€’ï¼šæ‰£å‡èƒ½é‡
                        // æ³¨æ„ï¼šå¦‚æœç›®æ ‡èŠ‚ç‚¹å°šæœªæ¿€æ´» (0.0)ï¼Œæ‰£å‡åä¸ºè´Ÿï¼Œä¹‹åä¼šè¢«æˆªæ–­
                        let entry = ontology_expanded.entry(edge.target_node_id).or_insert(0.0);
                        *entry -= energy; 
                    } else {
                        // æ™®é€šä¼ é€’
                        // V2: ç¡¬é˜ˆå€¼å‰ªæ (Hard Squelch)
                        if energy < 0.05 { continue; }
                        
                        let entry = ontology_expanded.entry(edge.target_node_id).or_insert(0.0);
                        *entry = (*entry).max(energy);
                    }
                }
            }
        }

        // --- Step 3: èƒ½é‡å½’ä¸€åŒ– (Energy Normalization) ---
        // é˜²æ­¢æ‰©æ•£åˆ° Memory åº“å‰èƒ½é‡è¿‡å¤§
        let total_energy: f32 = ontology_expanded.values().sum();
        if total_energy > 10.0 {
            let factor = 10.0 / total_energy;
            for val in ontology_expanded.values_mut() {
                *val *= factor;
            }
        }

        // --- Step 4: ç¬¬äºŒæ•°æ®åº“ (Memory è®°å¿†åº“) æ‰©æ•£ ---
        let final_scores = ontology_expanded.clone();
        let decay = 0.85; // æé«˜è¡°å‡ç³»æ•°ï¼Œå¢åŠ ä¿¡å·ä¼ æ’­è·ç¦»
        let layer_limit = 5000; 

        // ä¾§å‘æŠ‘åˆ¶ï¼šé€‰å‡ºèƒ½é‡æœ€é«˜çš„ Top-K ç§å­è¿›è¡Œæ‰©æ•£
        let mut seeds: Vec<(&i64, &f32)> = ontology_expanded.iter().collect();
        // æ’åº
        seeds.sort_by(|a, b| b.1.partial_cmp(a.1).unwrap());
        // æˆªæ–­ (Lateral Inhibition)
        if seeds.len() > layer_limit {
            seeds.truncate(layer_limit);
        }

        let increments: AHashMap<i64, f32> = seeds
            .into_iter()
            .fold(
                AHashMap::new(),
                |mut acc: AHashMap<i64, f32>, (&node_id, &score)| {
                    if let Some(neighbors) = self.graph.get(&node_id) {
                        for edge in neighbors {
                            let weight = edge.connection_strength as f32 / 65535.0;
                            
                            // V2: åå‘æŠ‘åˆ¶ (Memory å±‚)
                            let degree = self.in_degrees.get(&edge.target_node_id).unwrap_or(&1);
                            let inhibition_factor = 1.0 / (1.0 + (*degree as f32).log10());

                            let energy = score * weight * decay * inhibition_factor;
                            
                            // Memory å±‚é˜ˆå€¼ç¨ä½ï¼Œä¿ç•™æ›´å¤šç»†èŠ‚
                            if energy < 0.01 { continue; } 

                            *acc.entry(edge.target_node_id).or_default() += energy;
                        }
                    }
                    acc
                },
            );

        // --- Step 5: ç»“æœæ•´åˆä¸å±€éƒ¨ SimHash ç»†åŒ– ---
        let mut results_map = final_scores;
        for (id, energy) in increments {
            *results_map.entry(id).or_default() += energy;
        }

        let mut results: Vec<_> = results_map
            .into_iter()
            .filter(|(id, _)| self.nodes.get(id).map_or(false, |n| n.node_type == NodeType::Event))
            .collect();

        // å±€éƒ¨ç»†åŒ–ï¼šåªå¯¹åˆæ­¥æ’åºå‰ 50 çš„ç»“æœè¿›è¡Œ SimHash ä¿®æ­£
        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        for i in 0..results.len().min(50) {
            let (id, score) = &mut results[i];
            if let Some(node) = self.nodes.get(id) {
                // V2: åˆ†åŒºå¤šæ¨¡æ€å…±æŒ¯é€»è¾‘
                // 1. è¯­ä¹‰å…±æŒ¯ (åŸºç¡€)
                let semantic_sim = SimHash::similarity_weighted(query_fp, node.fingerprint, SimHash::MASK_SEMANTIC);
                let mut resonance_boost = semantic_sim * 0.6; // æ˜¾è‘—æå‡è¯­ä¹‰å…±æŒ¯æƒé‡
                
                // 2. æ—¶é—´å…±æŒ¯ (Temporal Resonance)
                // åªæœ‰å½“ Query æ˜¾å¼åŒ…å«æ—¶ç©ºä¿¡æ¯æ—¶ (mask åŒºåŸŸéé›¶)ï¼Œæ‰è¿›è¡ŒåŠ æƒ
                if (query_fp & SimHash::MASK_TEMPORAL) != 0 {
                    let temporal_sim = SimHash::similarity_weighted(query_fp, node.fingerprint, SimHash::MASK_TEMPORAL);
                    // æ—¶ç©ºåŒ¹é…ç»™äºˆé«˜æƒé‡ (0.5)ï¼Œæ¨¡æ‹Ÿâ€œç¬é—´å›å¿†â€
                    resonance_boost += temporal_sim * 0.5;
                }

                // 3. æƒ…æ„Ÿå…±é¸£ (Affective Resonance) - Bitwise AND
                if (query_fp & SimHash::MASK_AFFECTIVE) != 0 {
                    let query_emotions = (query_fp & SimHash::MASK_AFFECTIVE) >> 48;
                    let node_emotions = (node.fingerprint & SimHash::MASK_AFFECTIVE) >> 48;
                    
                    // ä½è¿ç®—å…±æŒ¯ï¼šåªè¦æœ‰å…±åŒçš„æƒ…æ„Ÿä½è¢«æ¿€æ´»ï¼Œå°±äº§ç”Ÿå¼ºçƒˆå…±é¸£
                    if (query_emotions & node_emotions) != 0 {
                        resonance_boost += 0.6; 
                    }
                }

                // 4. ç±»å‹å¯¹é½ (Entity Type Alignment)
                if (query_fp & SimHash::MASK_TYPE) != 0 {
                    let type_sim = SimHash::similarity_weighted(query_fp, node.fingerprint, SimHash::MASK_TYPE);
                    // ç±»å‹åŒ¹é…ç»™äºˆæé«˜çš„ä¿®æ­£æƒé‡ (0.8)ï¼Œå› ä¸ºç±»å‹ä¸å¯¹é€šå¸¸æ„å‘³ç€å®Œå…¨æ— å…³
                    resonance_boost += type_sim * 0.8;
                }

                // 5. è‰¾å®¾æµ©æ–¯è®°å¿†è¡°å‡ (Ebbinghaus Decay)
                // Formula: Energy = Base * e^(-t/tau)
                // ä½¿ç”¨ä¼ å…¥çš„ ref_time ä½œä¸ºè¡°å‡åŸºå‡†æ—¶é—´ (å¦‚æœä¸º 0 åˆ™é»˜è®¤ä¸è¡°å‡)
                let current_decay_time = if ref_time > 0 { ref_time } else { 1777593600 }; 
                let tau = 31536000.0; // å»¶é•¿è®°å¿†åŠè¡°æœŸ
                
                if node.timestamp > 0 && node.timestamp < current_decay_time {
                    let delta_t = (current_decay_time - node.timestamp) as f32;
                    let decay_factor = (-delta_t / tau).exp();
                    
                    // é™ä½è¡°å‡æ€»æƒé‡ï¼šé™åˆ¶è¡°å‡ç³»æ•°æœ€ä½ä¸º 0.8 (æ—§è®°å¿†æœ€å¤šæŸå¤± 20% èƒ½é‡)
                    let final_decay = decay_factor.max(0.8);
                    *score *= final_decay;
                }

                *score += resonance_boost;
            }
        }

        // --- ç¬¬å››é˜¶æ®µï¼šæ··æ²Œæ¿€æ´» (åŒè½¨å¹¶è¡Œ) ---
        if chaos_level > 0.0 {
            if let Some((query_fp, query_vec_f16)) = self.calculate_chaos(query) {
                let mut combined_results = AHashMap::new();
                
                // å°†ç†æ€§æ£€ç´¢ç»“æœå­˜å…¥ map (æŒ‰ 1 - chaos_level åŠ æƒ)
                for (id, score) in results.iter() {
                    combined_results.insert(*id, *score * (1.0 - chaos_level));
                }

                // --- 1. L1 ç²—æ’ (1-bit é‡åŒ–) ---
                // è®¡ç®—æ‰€æœ‰äº‹ä»¶èŠ‚ç‚¹çš„æ±‰æ˜è·ç¦»
                // ä¿ç•™å‰ 5000 ä¸ªå€™é€‰è€…
                
                // SoA æ‰«æ
                let mut candidates: Vec<(usize, u32)> = Vec::with_capacity(self.chaos_store.ids.len() / 10);

                for (idx, &node_fp) in self.chaos_store.fingerprints.iter().enumerate() {
                    // æ±‰æ˜è·ç¦»ï¼šå¼‚æˆ– -> ä½è®¡æ•° (ä¸åŒä½çš„æ•°é‡)
                    let distance = (query_fp ^ node_fp).count_ones();
                    
                    // é˜ˆå€¼å‰ªæï¼šæœ€å¤§è·ç¦» 64 (æ€»å…± 128 ä½) æ„å‘³ç€ç›¸å…³æ€§å‡ ä¹ä¸º 0
                    if distance < 64 {
                        candidates.push((idx, distance));
                    }
                }

                // æŒ‰è·ç¦»æ’åº (å‡åº)
                candidates.sort_unstable_by_key(|k| k.1);
                
                // æˆªå–å‰ 5000 ä¸ª
                if candidates.len() > 5000 {
                    candidates.truncate(5000);
                }

                // --- 2. L2 ç²¾æ’ (f16 ä½™å¼¦ç›¸ä¼¼åº¦) ---
                let q_norm: f32 = query_vec_f16.iter().map(|x| x.to_f32().powi(2)).sum::<f32>().sqrt();
                
                for (idx, _dist) in candidates {
                    let node_id = self.chaos_store.ids[idx];
                    let chaos_vector = &self.chaos_store.vectors[idx];

                    if !chaos_vector.is_empty() {
                        let dot: f32 = query_vec_f16.iter().zip(chaos_vector).map(|(a, b)| a.to_f32() * b.to_f32()).sum();
                        let n_norm: f32 = chaos_vector.iter().map(|x| x.to_f32().powi(2)).sum::<f32>().sqrt();
                        
                        if q_norm > 0.0 && n_norm > 0.0 {
                            let sim = dot / (q_norm * n_norm);
                            
                            // éçº¿æ€§æ¿€æ´» (é˜ˆå€¼ > 0.95, æœ€å¤§ç³»æ•° 0.15)
                            if sim > 0.95 {
                                let normalized = (sim - 0.95) / 0.05;
                                let chaos_score = normalized * 0.15;
                                let weighted_chaos = chaos_score * chaos_level;
                                
                                *combined_results.entry(node_id).or_default() += weighted_chaos;
                            }
                        }
                    }
                }
                
                // è½¬æ¢å›æ’åºåçš„å‘é‡
                let mut final_results: Vec<_> = combined_results.into_iter().collect();
                final_results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
                return final_results;
            }
        }
        
        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        results
    }

    /// æ¨¡æ‹Ÿ LLM ç»´æŠ¤è¿‡ç¨‹ï¼šå¯¹è¯ååˆ†æå…³é”®è¯å…³è”å¹¶æ›´æ–° Ontology
    /// V2: é€»è¾‘ä»²è£è§¦å‘å™¨ (Logical Arbitration Trigger)
    /// å½“ action ä¸º "replace" æ—¶è°ƒç”¨æ­¤å‡½æ•°
    /// è¿”å›å€¼ï¼šéœ€è¦å‘é€ç»™ LLM2 (ä»²è£è€…) çš„ Context (å±€éƒ¨å­å›¾æ–‡æœ¬)
    pub fn trigger_arbitration(&self, source: &str) -> Option<String> {
        let src_id = self.keyword_to_node.get(&source.to_lowercase())?;
        
        // æå– 1-hop å­å›¾
        // æ ¼å¼: "Source -> Target (Strength: 0.x)"
        let mut context_lines = Vec::new();
        if let Some(edges) = self.ontology_graph.get(src_id) {
            for edge in edges {
                if let Some(target_node) = self.nodes.get(&edge.target_node_id) {
                    let strength = edge.connection_strength as f32 / 65535.0;
                    context_lines.push(format!("{} -> {} (Strength: {:.2})", 
                        source, target_node.content, strength));
                }
            }
        }
        
        if context_lines.is_empty() {
            return None;
        }
        
        Some(context_lines.join("\n"))
    }

    /// V2: æ‰§è¡Œä»²è£ç»“æœ (Apply Arbitration)
    /// æ ¹æ® LLM2 çš„æŒ‡ç¤ºåˆ é™¤æŒ‡å®šå…³è”
    pub fn apply_arbitration(&mut self, source: &str, delete_targets: Vec<String>) {
        if let Some(&src_id) = self.keyword_to_node.get(&source.to_lowercase()) {
            if let Some(edges) = self.ontology_graph.get_mut(&src_id) {
                let initial_len = edges.len();
                
                // è¿‡æ»¤æ‰éœ€è¦åˆ é™¤çš„ç›®æ ‡
                // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦é€šè¿‡ target content åæŸ¥ idï¼Œæˆ–è€…éå† edges æ£€æŸ¥ content
                // ä¸ºäº†æ€§èƒ½ï¼Œæˆ‘ä»¬å…ˆæ”¶é›†è¦åˆ é™¤çš„ target_ids
                let mut target_ids_to_remove = Vec::new();
                
                for target_str in delete_targets {
                    if let Some(&tgt_id) = self.keyword_to_node.get(&target_str.to_lowercase()) {
                        target_ids_to_remove.push(tgt_id);
                    }
                }
                
                if !target_ids_to_remove.is_empty() {
                    edges.retain(|e| !target_ids_to_remove.contains(&e.target_node_id));
                    let removed_count = initial_len - edges.len();
                    if removed_count > 0 {
                        println!("âœ‚ï¸ [Arbitration] å·²ä» '{}' ç§»é™¤ {} æ¡è¿‡æ—¶å…³è”", source, removed_count);
                    }
                }
            }
        }
    }

    pub fn maintain_ontology(&mut self, source: &str, target: &str, relation_type: &str, strength: f32) {
        println!("ğŸ¤– [LLM Maintenance] å‘ç°æ–°å…³è”: {} -> {} (type: {}, strength: {})", 
                 source, target, relation_type, strength);
        
        let src_id = self.get_or_create_feature(source);
        let tgt_id = self.get_or_create_feature(target);
        
        let strength_u16 = (strength * 65535.0) as u16;
        
        // ç¡®å®šè¾¹ç±»å‹ (ç®€åŒ–ä¸ºä¸‰ç§æ ¸å¿ƒé€»è¾‘)
        let edge_type = match relation_type.to_lowercase().as_str() {
            "equality" | "equal" => SimHash::EDGE_EQUALITY,
            "inhibition" | "conflict" => SimHash::EDGE_INHIBITION,
            _ => SimHash::EDGE_REPRESENTATION,
        };

        // å¤„ç†æ­£å‘è¾¹
        {
            let edges = self.ontology_graph.entry(src_id).or_insert(SmallVec::new());
            if let Some(existing) = edges.iter_mut().find(|e| e.target_node_id == tgt_id) {
                // [LTD æœºåˆ¶] è¢«åŠ¨å¼ºåŒ– (Hebbian Learning)
                existing.connection_strength = existing.connection_strength.saturating_add(strength_u16 / 2).max(strength_u16);
                // æ›´æ–°ç±»å‹
                existing.edge_type = edge_type;
            } else {
                edges.push(GraphEdge {
                    target_node_id: tgt_id,
                    connection_strength: strength_u16,
                    edge_type,
                });
            }
        }
        
        // å¤„ç†åå‘è¾¹
        // 1. Equality (Type 1): å¼ºåˆ¶åŒå‘ï¼Œè¡¨ç¤º A==B ä¸” B==A
        // 2. Inhibition (Type 255): å¼ºåˆ¶åŒå‘ï¼Œè¡¨ç¤º Aäº’æ–¥B ä¸” Bäº’æ–¥A
        // 3. Representation (Type 0): é»˜è®¤å•å‘ (Directed)ï¼Œå› ä¸º"çœ‹åˆ°Bæƒ³åˆ°A"ä¸ä»£è¡¨"çœ‹åˆ°Aä¸€å®šæƒ³åˆ°B"
        //    (é™¤éä¸šåŠ¡å±‚æ˜¾å¼è¦æ±‚åŒå‘ï¼Œå¦åˆ™åº•å±‚åªå­˜å•å‘)
        if edge_type == SimHash::EDGE_EQUALITY || edge_type == SimHash::EDGE_INHIBITION {
            let rev_edges = self.ontology_graph.entry(tgt_id).or_insert(SmallVec::new());
            if let Some(existing) = rev_edges.iter_mut().find(|e| e.target_node_id == src_id) {
                // [LTD æœºåˆ¶] è¢«åŠ¨å¼ºåŒ–
                existing.connection_strength = existing.connection_strength.saturating_add(strength_u16 / 2).max(strength_u16);
                existing.edge_type = edge_type;
            } else {
                rev_edges.push(GraphEdge {
                    target_node_id: src_id,
                    connection_strength: strength_u16,
                    edge_type,
                });
            }
        }
    }

    /// V2: Ontology å‰ªææœºåˆ¶ (Noise Pruning)
    /// 1. å…¨å±€ä½æƒæ¸…ç†: åˆ é™¤ strength < 0.1 çš„è¾¹
    /// 2. å±€éƒ¨å®¹é‡é™åˆ¶: æ¯ä¸ªèŠ‚ç‚¹æœ€å¤šä¿ç•™ 100 æ¡è¾¹
    /// å»ºè®®è°ƒç”¨æ—¶æœº: æ¯æ¬¡ä¿å­˜å‰ï¼Œæˆ–æ¯å¤©ä¸€æ¬¡
    pub fn prune_ontology(&mut self) {
        println!("ğŸ§¹ [Pruning] å¼€å§‹æ‰§è¡Œ Ontology å‰ªæ...");
        let threshold = (0.05 * 65535.0) as u16; // é˜ˆå€¼ 0.05
        let max_edges = 100;
        let mut total_removed = 0;
        
        // è°ƒç”¨æ–°çš„å…¨å±€è¡°å‡ä¸å‰ªæé€»è¾‘
        // è¡°å‡ 1% (0.99)
        total_removed += self.apply_global_decay_and_pruning(0.99, threshold);

        for (_node_id, edges) in self.ontology_graph.iter_mut() {
            let initial_len = edges.len();
            
            // 1. å…¨å±€ä½æƒæ¸…ç† (å·²ç”± apply_global_decay_and_pruning å¤„ç†)
            // edges.retain(|e| e.connection_strength >= threshold);
            
            // 2. å±€éƒ¨å®¹é‡é™åˆ¶
            if edges.len() > max_edges {
                // æŒ‰å¼ºåº¦é™åºæ’åº
                edges.sort_by(|a, b| b.connection_strength.cmp(&a.connection_strength));
                // æˆªæ–­
                edges.truncate(max_edges);
            }
            
            total_removed += initial_len - edges.len();
        }
        
        println!("âœ¨ [Pruning] å‰ªæå®Œæˆï¼Œå…±æ¸…ç†äº† {} æ¡ä½ä»·å€¼/æº¢å‡ºå…³è”ã€‚", total_removed);
    }

    /// ç»Ÿä¸€ç»´æŠ¤æ¥å£ (Unified Maintenance Interface)
    /// è‡ªåŠ¨å¤„ç† upsert/replace é€»è¾‘
    /// è¿”å›å€¼: Option<String> - å¦‚æœéœ€è¦ä»²è£ (Replace æ¨¡å¼)ï¼Œè¿”å› 1-hop å±€éƒ¨å­å›¾ä¸Šä¸‹æ–‡ï¼›å¦åˆ™è¿”å› None
    pub fn execute_maintenance(&mut self, action: &str, source: &str, target: &str, relation_type: &str, strength: f32, _reason: &str) -> Option<String> {
        match action.to_lowercase().as_str() {
            "upsert" => {
                // Upsert: ç›´æ¥ç»´æŠ¤æœ¬ä½“å…³è”
                self.maintain_ontology(source, target, relation_type, strength);
                None
            },
            "replace" => {
                // Replace: å…ˆåº”ç”¨æ–°å˜æ›´ï¼Œç„¶åè§¦å‘ä»²è£
                // è¿™æ · LLM2 èƒ½çœ‹åˆ°å†²çªçš„å…¨è²Œ (æ—§ + æ–°)
                self.maintain_ontology(source, target, relation_type, strength);
                self.trigger_arbitration(source)
            },
            _ => {
                println!("âš ï¸ æœªçŸ¥æ“ä½œ: {} (Source: {})", action, source);
                None
            }
        }
    }
}

    // Benchmark functions removed


// Main function removed for WASM compatibility
